<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>How to deploy the new Grafana Tempo operator on OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/08/01/how-deploy-new-grafana-tempo-operator-openshift" /><author><name>Pavol Loffay</name></author><id>e2c1f40d-0262-4d1e-92a6-f3ac577f6d19</id><updated>2023-08-01T07:00:00Z</updated><published>2023-08-01T07:00:00Z</published><summary type="html">&lt;p&gt;The distributed tracing team at Red Hat is excited to announce the &lt;a href="https://github.com/grafana/tempo-operator"&gt;Tempo operator&lt;/a&gt; technology preview product on Red Hat OpenShift as part of distributed tracing. We have released Tempo operator to all supported OpenShift versions (4.10 and above).&lt;/p&gt; &lt;p&gt;In this article, we will describe the Tempo operator and features available on OpenShift. The Tempo operator is also available to the upstream Kubernetes users through &lt;a href="https://operatorhub.io/operator/tempo-operator"&gt;operatorhub.io&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Why use Grafana Tempo?&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://grafana.com/docs/tempo/latest/"&gt;Tempo documentation&lt;/a&gt; states, “Grafana Tempo is an open source, easy-to-use, and high-volume distributed tracing backend. Tempo is cost-efficient and only requires object storage to operate. Tempo is deeply integrated with Grafana, Mimir, Prometheus, and Loki. You can use Tempo with open-source tracing protocols, including Jaeger, Zipkin, or OpenTelemetry.”&lt;/p&gt; &lt;p&gt;Why Tempo? Tempo aligns well with other Red Hat observability products (e.g., Prometheus and Loki). It also uses object storage to store data, has similar design, and therefore it should be operationally similar to the other observability backends. We believe that Tempo is a good choice, and it will give OpenShift users great user experience and improve observability capabilities.&lt;/p&gt; &lt;p&gt;One of the exciting Tempo features is &lt;a href="https://grafana.com/docs/tempo/latest/traceql/"&gt;TraceQL&lt;/a&gt;. It is a query language inspired by &lt;a href="https://prometheus.io/docs/prometheus/latest/querying/basics/"&gt;PromQL&lt;/a&gt; and &lt;a href="https://grafana.com/docs/loki/latest/logql/"&gt;LogQL&lt;/a&gt;. In the upcoming releases, OpenShift users will be able to use similar language to query all telemetry signals.&lt;/p&gt; &lt;p&gt;Tempo can be deployed in &lt;a href="https://grafana.com/docs/tempo/latest/setup/deployment/#monolithic-mode"&gt;monolithic&lt;/a&gt; and &lt;a href="https://grafana.com/docs/tempo/latest/setup/deployment/#microservices-mode"&gt;microservices&lt;/a&gt; mode. The current Tempo operator supports only the microservices mode, which creates several deployments for Tempo components (Figure 1).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/tempo_arch.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/tempo_arch.png?itok=qH_wI9BC" width="600" height="390" alt="A screenshot of the Grafana Tempo architecture." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The Grafana Tempo architecture.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;The Tempo operator features&lt;/h2&gt; &lt;p&gt;The Tempo operator manages TempoStack &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;Custom Resource Definition&lt;/a&gt; (CRD) that allows users to create Tempo instances the Kubernetes native way. It simplifies Tempo installation by giving users a curated set of configuration options and hides operational complexity by handling automated upgrades, for instance.&lt;/p&gt; &lt;p&gt;The operator features:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Resource management&lt;/strong&gt;: A single resource definition splitS across all Tempo containers.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Authentication and authorization:&lt;/strong&gt; OIDC with static RBAC or integration with OpenShift OAuth and SubjectAccessReview.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Security:&lt;/strong&gt; Internal communication is protected with mTLS.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Automated monitoring:&lt;/strong&gt; The operator configures Prometheus service monitors to scrape metrics from Tempo deployments.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Networking:&lt;/strong&gt; The Jaeger UI is exposed via the OpenShift route.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;The Tempo user interface&lt;/h3&gt; &lt;p&gt;The upstream Tempo project does not have any native user interface, however the TempoStack can be configured to deploy a Jaeger query with the Jaeger UI. This configuration option not only allows users to use Jaeger UI, but also exposes the Jaeger query APIs.&lt;/p&gt; &lt;p&gt;Grafana users can configure the Tempo datasource and use externally managed Grafana as a visualization tool for Tempo.&lt;/p&gt; &lt;p&gt;The following fraction of the TempoStack CR enables the Jaeger UI:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: tempo.grafana.com/v1alpha1 kind: TempoStack metadata:   name: simplest spec:   template:     queryFrontend:       jaegerQuery:         enabled: true&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Object storage&lt;/h3&gt; &lt;p&gt;The Tempo operator supports OpenShift Data Foundation, AWS S3, Azure, GCS and Minio for storing Tempo data. Follow the &lt;a href="https://tempo-operator.netlify.app/docs/object_storage.md/"&gt;operator docs&lt;/a&gt; to learn how to create a secret for connecting to your preferred storage option.&lt;/p&gt; &lt;h2&gt;How to install the Tempo operator&lt;/h2&gt; &lt;p&gt;On OpenShift, you can install the operator directly from the Operator Hub (Figure 2). The Operator Hub will show two Tempo operators: the community distribution and the supported Red Hat OpenShift distributed tracing product:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_of_operatorhub_red_hat_openshift_dedicated.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_of_operatorhub_red_hat_openshift_dedicated.jpg?itok=vqCkZ7Oa" width="600" height="280" alt="A screenshot of the Operator Hub page on OpenShift." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-license field--type-entity-reference field--label-inline field__items"&gt; &lt;span class="field__label"&gt;License&lt;/span&gt; &lt;span class="rhd-media-licence field__item"&gt; under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" title="Apache 2.0"&gt;Apache 2.0&lt;/a&gt;. &lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The Operator Hub on OpenShift.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;A multitenancy example&lt;/h3&gt; &lt;p&gt;Tempo is a native multitenant system. On OpenShift, the Tempo operator deploys a gateway that uses OpenShift OAuth (reading) and TokenReview (writing) for authentication, and SubjectAccessReview for authorization.&lt;/p&gt; &lt;p&gt;The following TempoStack CR enables authentication with multitenancy and configures two tenants with the names, dev and prod. The example uses S3 object storage with secret tempostack-dev-minio. Refer to the &lt;a href="https://tempo-operator.netlify.app/docs/object_storage.md/"&gt;documentation&lt;/a&gt; to learn how to set it up.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kubectl apply -f - &lt;&lt;EOF apiVersion: tempo.grafana.com/v1alpha1 kind:  TempoStack metadata:   name: simplest   namespace: observability spec:   storage:     secret:       name: tempostack-dev-minio       type: s3   storageSize: 1Gi   resources:     total:       limits:         memory: 2Gi         cpu: 2000m   tenants:     mode: openshift     authentication:       - tenantName: dev         tenantId: "1610b0c3-c509-4592-a256-a1871353dbfa"       - tenantName: prod         tenantId: "6094b0f1-711d-4395-82c0-30c2720c6648"   template:     gateway:       enabled: true     queryFrontend:       jaegerQuery:         enabled: true EOF&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These are the main objects created by the operator:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;NAME                                              HOST/PORT                                               PATH   SERVICES                 PORT     TERMINATION   WILDCARD route.route.openshift.io/tempo-simplest-gateway   tempo-simplest-gateway-observability.apps-crc.testing          tempo-simplest-gateway   public   passthrough   None NAME                                              TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                                             AGE service/tempo-simplest-compactor                  ClusterIP   10.217.5.105   &lt;none&gt;        7946/TCP,3200/TCP                                                   18h service/tempo-simplest-distributor                ClusterIP   10.217.4.38    &lt;none&gt;        4317/TCP,3200/TCP                                                   18h service/tempo-simplest-gateway                    ClusterIP   10.217.5.27    &lt;none&gt;        8090/TCP,8081/TCP,8080/TCP                                          18h service/tempo-simplest-gossip-ring                ClusterIP   None           &lt;none&gt;        7946/TCP                                                            18h service/tempo-simplest-ingester                   ClusterIP   10.217.4.27    &lt;none&gt;        3200/TCP,9095/TCP                                                   18h service/tempo-simplest-querier                    ClusterIP   10.217.4.65    &lt;none&gt;        7946/TCP,3200/TCP,9095/TCP                                          18h service/tempo-simplest-query-frontend             ClusterIP   10.217.4.222   &lt;none&gt;        3200/TCP,9095/TCP,16686/TCP,16687/TCP                               18h service/tempo-simplest-query-frontend-discovery   ClusterIP   None           &lt;none&gt;        3200/TCP,9095/TCP,9096/TCP,16686/TCP,16687/TCP                      18h NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE deployment.apps/tempo-simplest-compactor        1/1     1            1           18h deployment.apps/tempo-simplest-distributor      1/1     1            1           18h deployment.apps/tempo-simplest-gateway          1/1     1            1           18h deployment.apps/tempo-simplest-querier          1/1     1            1           18h deployment.apps/tempo-simplest-query-frontend   1/1     1            1           18h NAME                                       READY   AGE statefulset.apps/tempo-simplest-ingester   1/1     18h&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The operator creates a tempo-simplest-gateway route to access the UI, however we need to create a ClusterRole to allow users accessing the UI. The following ClusterRole gives all OpenShift authenticated users access to the dev tenant. Then the Jaeger UI can be accessed on this URL: https://tempo-simplest-gateway-observability.{OpenShift base domain}/api/traces/v1/dev/search).&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kubectl apply -f - &lt;&lt;EOF apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:   name: tempostack-traces-reader rules:   - apiGroups:       - 'tempo.grafana.com'     resources:       - dev     resourceNames:       - traces     verbs:       - 'get' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:   name: tempostack-traces-reader roleRef:   apiGroup: rbac.authorization.k8s.io   kind: ClusterRole   name: tempostack-traces-reader subjects:   - kind: Group     apiGroup: rbac.authorization.k8s.io     name: system:authenticated EOF&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To write, the data clients (e.g., OpenTelemetry collector) have to send the X-Scope-OrgID header with the tenant name (e.g., dev) and Kubernetes ServiceAccount token (e.g., /var/run/secrets/kubernetes.io/serviceaccount/token) as a bearer token. Therefore, the client’s ServiceAccount has to be associated with the ClusterRole giving write access for a given tenant.&lt;/p&gt; &lt;p&gt;The following example creates an OpenTelemetry collector and configures it to send data to the previously deployed Tempo:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kubectl apply -f - &lt;&lt;EOF --- apiVersion: opentelemetry.io/v1alpha1 kind: OpenTelemetryCollector metadata:   name: dev   namespace: observability spec:   config: |     extensions:       bearertokenauth:         filename: "/var/run/secrets/kubernetes.io/serviceaccount/token"     receivers:       otlp:         protocols:           grpc:           http:       jaeger:         protocols:           thrift_binary:           thrift_compact:           thrift_http:           grpc:     processors:     exporters:       logging:       otlp:         endpoint: tempo-simplest-gateway.observability.svc.cluster.local:8090         tls:           insecure: false           ca_file: "/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt"         auth:           authenticator: bearertokenauth         headers:           X-Scope-OrgID: "dev"     service:       extensions: [bearertokenauth]       pipelines:         traces:           receivers: [otlp, jaeger]           exporters: [otlp, logging] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:   name: tempostack-traces-write rules:   - apiGroups:       - 'tempo.grafana.com'     resources:       - dev     resourceNames:       - traces     verbs:       - 'create' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata:   name: tempostack-traces roleRef:   apiGroup: rbac.authorization.k8s.io   kind: ClusterRole   name: tempostack-traces-write subjects:   - kind: ServiceAccount     name: dev-collector     namespace: observability EOF&lt;/code&gt;&lt;/pre&gt; &lt;div&gt; &lt;/div&gt; &lt;p&gt;We have successfully configured and deployed tracing data collection and storage. Now we can deploy an example application that will generate traces and report them to the OpenTelemetry collector:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kubectl apply -f - &lt;&lt;EOF apiVersion: batch/v1 kind: Job metadata:   name: telemetrygen   namespace: observability   labels:     app: telmeetrygen spec:   ttlSecondsAfterFinished: 30   template:     spec:       restartPolicy: OnFailure       containers:       - name: telemetrygen         image: ghcr.io/open-telemetry/opentelemetry-collector-contrib/telemetrygen:v0.74.0         args: [traces, --otlp-endpoint=dev-collector:4317, --otlp-insecure, --duration=240s, --rate=4] EOF&lt;/code&gt;&lt;/pre&gt; &lt;div&gt; &lt;/div&gt; &lt;p&gt;The Jaeger UI can be accessed on the URL: https://tempo-simplest-gateway-observability.apps-crc.testing/api/traces/v1/dev/search. This URL is from my &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;local CRC cluster&lt;/a&gt;. The dev in the URL denotes the dev tenant (Figure 3).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_of_jaeger_ui_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_of_jaeger_ui_0.jpg?itok=S8-N8avh" width="600" height="304" alt="A screenshot of the Jaeger UI trace search." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;span class="field field--name-field-license field--type-entity-reference field--label-inline field__items"&gt; &lt;span class="field__label"&gt;License&lt;/span&gt; &lt;span class="rhd-media-licence field__item"&gt; under &lt;a href="https://www.apache.org/licenses/LICENSE-2.0" title="Apache 2.0"&gt;Apache 2.0&lt;/a&gt;. &lt;/span&gt; &lt;/span&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The Jaeger UI trace search.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Deploying the Tempo operator is simple&lt;/h2&gt; &lt;p&gt;Deploying Tempo with the operator is a straightforward process and gives users a curated set of configuration options that are relevant for running Tempo on Kubernetes. The integration with OpenShift OAuth makes authentication simple and well integrated into the platform. The Tempo operator is a new project. We are looking forward to future releases to further improve user experience and give users exciting capabilities, such as TraceQL, span RED metrics, auto-tuning of configuration parameters, and automating Tempo operation.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/08/01/how-deploy-new-grafana-tempo-operator-openshift" title="How to deploy the new Grafana Tempo operator on OpenShift"&gt;How to deploy the new Grafana Tempo operator on OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Pavol Loffay</dc:creator><dc:date>2023-08-01T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.41.0 released!</title><link rel="alternate" href="https://blog.kie.org/2023/07/kogito-1-41-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2023/07/kogito-1-41-0-released.html</id><updated>2023-07-31T11:29:40Z</updated><content type="html">We are glad to announce that the Kogito 1.41.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Serverless Workflow Python support. See   * Upgrade Serverless Workflow SDK Java to 4.0.4 For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.30.0 artifacts are available at the . A detailed changelog for 1.41.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>How to handle transactions in Node.js reference architecture</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/31/how-handle-transactions-nodejs-reference-architecture" /><author><name>Michael Dawson</name></author><id>9ebaf8e2-b7d9-40c7-b416-097082c4f22d</id><updated>2023-07-31T07:00:00Z</updated><published>2023-07-31T07:00:00Z</published><summary type="html">&lt;p&gt;In many applications, completing more than a single update as an atomic unit (transaction) is needed to preserve data integrity. This installment of the ongoing &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js Reference Architecture&lt;/a&gt; series covers the Node.js reference architecture team’s experience with integrating transactions into your application to satisfy this requirement.&lt;/p&gt; &lt;p&gt;Follow the series:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Part 1: &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Overview of the Node.js reference architecture&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 2: &lt;a href="https://developer.ibm.com/blogs/nodejs-reference-architectire-pino-for-logging/"&gt;Logging in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/05/17/introduction-nodejs-reference-architecture-part-3-code-consistency"&gt;Code consistency in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 4: &lt;a href="https://developers.redhat.com/articles/2021/06/22/introduction-nodejs-reference-architecture-part-4-graphql-nodejs"&gt;GraphQL in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 5: &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 6: &lt;a href="https://developers.redhat.com/articles/2021/12/03/introduction-nodejs-reference-architecture-part-6-choosing-web-frameworks"&gt;Choosing web frameworks&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 7: &lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage"&gt;Code Coverage&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 8: &lt;a href="https://developers.redhat.com/articles/2022/04/11/introduction-nodejs-reference-architecture-part-8-typescript"&gt;Typescript&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 9: &lt;a href="https://developers.redhat.com/articles/2022/08/09/8-elements-securing-nodejs-applications"&gt;Securing Node.js applications&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 10: &lt;a href="https://developers.redhat.com/articles/2022/11/03/nodejs-reference-architecture-part-10-accessibility"&gt;Accessibility&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 11: &lt;a href="https://developers.redhat.com/articles/2022/12/21/typical-development-workflows"&gt;Typical development workflows&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 12: &lt;a href="https://developers.redhat.com/articles/2023/02/22/installing-nodejs-modules-using-npm-registry"&gt;Npm development&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 13: &lt;a href="https://developers.redhat.com/articles/2023/03/21/how-investigate-7-common-problems-production#"&gt;Problem determination&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Part 14: &lt;a href="https://developers.redhat.com/articles/2023/07/27/introduction-nodejs-reference-architecture-testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Part 15: Transaction handling&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Ecosystem support for transactions&lt;/h2&gt; &lt;p&gt;Unlike the Java ecosystem, there are no well-established application servers with built in support for transactions and no JavaScript specific standards for transactions. Instead, Node.js applications either depend on the transaction support within &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/functional-components/databases.md"&gt;databases&lt;/a&gt; and their related Node.js clients and/or use patterns which are needed when business logic is spread over a number of microservices. These patterns include:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;a href="https://www.educative.io/answers/what-is-the-two-phase-commit-protocol"&gt;2 phase commit&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://medium.com/trendyol-tech/saga-pattern-briefly-5b6cf22dfabc"&gt;Saga pattern&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Leveraging database support for transactions&lt;/h2&gt; &lt;p&gt;In the team's experience, if the updates that need to be completed atomically can be handled by a single Node.js component, and you are using a database with support for transactions that is the easiest case.&lt;/p&gt; &lt;p&gt;In some Node.js database clients, there is no specific support for transactions in the client, but that does not mean that transactions are not supported. Instead transactions are managed by using protocol level statements (for example BEGIN/COMMIT in SQL). &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; is one of those databases. A simple example of using a transaction from the node-postgres client &lt;a href="https://node-postgres.com/features/transactions"&gt;documentation&lt;/a&gt; is as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;const { Pool } = require('pg') const pool = new Pool() const client = await pool.connect() try { await client.query('BEGIN') const queryText = 'INSERT INTO users(name) VALUES($1) RETURNING id' const res = await client.query(queryText, ['brianc']) const insertPhotoText = 'INSERT INTO photos(user_id, photo_url) VALUES ($1, $2)' const insertPhotoValues = [res.rows[0].id, 's3.bucket.foo'] await client.query(insertPhotoText, insertPhotoValues) await client.query('COMMIT') } catch (e) { await client.query('ROLLBACK') throw e } finally { client.release() } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the team's experience transactions work best with async/await versus generators, and it is good to have a try/catch around the rollback sections in addition to those which do the commit.&lt;/p&gt; &lt;h2&gt;The challenges of microservices&lt;/h2&gt; &lt;p&gt;In the team’s experience, the more common case is that a Node.js application incorporates a number of microservices, each of which might have a connection to the database or even may store data across different types or instances of datastores.&lt;/p&gt; &lt;p&gt;The challenges that come with implementing transactions with microservices are not unique to Node.js and the common approaches include:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;a href="https://www.educative.io/answers/what-is-the-two-phase-commit-protocol"&gt;2 phase commit&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://medium.com/trendyol-tech/saga-pattern-briefly-5b6cf22dfabc"&gt;Saga pattern&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;These are also used in Node.js applications.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture#what_is_the_problem_"&gt;Patterns for distributed transactions within a microservices architecture&lt;/a&gt; provides a nice overview of the challenges introduced when managing transactions across microservices and these two patterns.&lt;/p&gt; &lt;p&gt;In the team's experience, Node.js applications will most often use the Saga pattern as opposed to two-phase commit, in part since the microservices may not share the same data store.&lt;/p&gt; &lt;p&gt;When two-phase commit is used, it will have to depend on external support from an underlying data store. Some databases offer support to help with implementing the two-phase commit technique, so read through the documentation for the database you are using if you are planning to use that technique.&lt;/p&gt; &lt;h2&gt;Learn more about Node.js reference architecture&lt;/h2&gt; &lt;p&gt;I hope that this quick overview of the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/functional-components/transaction-handling.md"&gt;transaction handling&lt;/a&gt; part of the Node.js reference architecture, along with the team discussions that led to that content, has been helpful, and that the information shared in the architecture helps you in your future implementations. We plan to cover new topics regularly for the Node.js reference architecture series. Until the next installment, we invite you to visit the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub, where you will see the work we have done and future topics.&lt;/p&gt; &lt;p&gt;To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/31/how-handle-transactions-nodejs-reference-architecture" title="How to handle transactions in Node.js reference architecture"&gt;How to handle transactions in Node.js reference architecture&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Dawson</dc:creator><dc:date>2023-07-31T07:00:00Z</dc:date></entry><entry><title>Quarkus 2.16.9.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-16-9-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-16-9-final-released/</id><updated>2023-07-31T00:00:00Z</updated><published>2023-07-31T00:00:00Z</published><summary type="html">As mentioned in previous blog posts, we encourage all our users to upgrade to Quarkus 3 (it is an easy task with quarkus update). However we understand the migration can require some time so we will continue to maintain 2.16.x for a while. Today, we released Quarkus 2.16.9.Final, the ninth...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-07-31T00:00:00Z</dc:date></entry><entry><title type="html">How to Upload and Download Files with a Servlet</title><link rel="alternate" href="https://www.mastertheboss.com/java-ee/servlet-30/uploading-a-file-with-a-servlet/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/java-ee/servlet-30/uploading-a-file-with-a-servlet/</id><updated>2023-07-30T08:50:59Z</updated><content type="html">This article will illustrate how to upload files using the Jakarta Servlet API. We will also learn how to use a Servlet to download a File that is available remotely on the Server. Uploading Files with a Servlet By using Jakarta Servlet API it is pretty simple to upload a File without the need of ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>DevNation Day: Modern App Dev videos are now available</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/28/devnation-day-modern-app-dev-videos-are-now-available" /><author><name>Valentina Rodriguez Sosa</name></author><id>e588c9d2-ed9d-44b6-ad76-67949bc05ad7</id><updated>2023-07-28T13:00:00Z</updated><published>2023-07-28T13:00:00Z</published><summary type="html">&lt;p&gt;Last month Red Hat Developer hosted &lt;a href="https://developers.redhat.com/devnation/dnd"&gt;DevNation Day: Modern App Dev&lt;/a&gt;. This one-day virtual event brought together application developers, DevOps and platform engineers, enterprise architects, and application managers from across the globe.&lt;/p&gt; &lt;p&gt;Attendees participated in hands-on labs and got expert advice from Red Hat practitioners on best practices, technologies, and architectures advancing the state of modern application development on the hybrid cloud with &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. The event featured talks on app modernization, &lt;a href="https://developers.redhat.com/topics/api-management/"&gt;APIs&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;serverless&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/security/"&gt;security&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;, &lt;a href="https://developers.redhat.com/articles/2023/05/23/developers-guide-red-hat-developer-hub-and-janus/"&gt;internal developer platforms&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/red-hat-architecture-and-design-patterns"&gt;application architecture&lt;/a&gt;, and much more.&lt;/p&gt; &lt;p&gt;The videos from DevNation Day: Modern App Dev are now available for you to watch online anytime. Read on to explore some of the highlights, or &lt;a href="https://www.youtube.com/playlist?list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41"&gt;jump right over to the playlist&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Keynote: Becoming the developer's developer&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href="https://developers.redhat.com/authors/burr-sutter/"&gt;Burr Sutter, Director of Developer Experience&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In his DevNation Day keynote &lt;a href="https://www.youtube.com/watch?v=TRE2lJwsDlk"&gt;Becoming the developer's developer&lt;/a&gt;, Burr presents challenges and opportunities for teams delivering software to production today. This engaging talk covers a range of topics including platform engineering, &lt;a href="https://developers.redhat.com/topics/devsecops"&gt;DevSecOps&lt;/a&gt;, software as a team effort, and the importance of reducing cognitive load for developers and providing the tools they need to build better applications. He also shares resources to help you build an understanding of what it means to build better software within your organization. &lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;Breaking silo with Ansible&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session:&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=6-bcVni0ej8&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=1"&gt;Breaking silo with Ansible&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href="https://developers.redhat.com/author/romain-pelisse"&gt;Roman Pelisse, Senior Software Engineer&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The effective operation of software infrastructure requires rigorous &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt;, regardless of where it is hosted: on-premise, in the cloud, at the edge, and everything in between. Each step an application takes throughout its software development life cycle on its way from development to production should be managed in an automated fashion. Organizations have traditionally struggled to adopt a holistic automation approach due to the division between development and operations.&lt;/p&gt; &lt;p&gt;In this session, Romain Pelisse demonstrates how &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Ansible&lt;/a&gt; can become the lingua franca to help break the walls between these organizational units and drive real business value.&lt;/p&gt; &lt;h2&gt;Quarkus for Spring developers&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session:&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=AxNiHJAbJSc&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=13"&gt;Quarkus for Spring developers&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href="https://developers.redhat.com/author/eric-deandrea"&gt;Eric Deandrea, Senior Principal Technical Marketing Manager&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In this session, Eric Deandrea discusses concepts and conventions familiar to &lt;a href="https://developers.redhat.com/topics/spring-boot/"&gt;Spring&lt;/a&gt; developers and how they can be implemented in Quarkus, explaining the similarities and differences between them. You'll also explore similarities and differences in how &lt;a href="https://developers.redhat.com/articles/2021/11/08/test-driven-development-quarkus"&gt;testing&lt;/a&gt; is done, with a look at Quarkus Dev Services and continuous testing.&lt;/p&gt; &lt;p&gt;This session is focused on live coding; Eric takes an existing Spring application with a full test suite and builds a Quarkus equivalent version of it live. &lt;/p&gt; &lt;p class="Indent1"&gt;[ &lt;strong&gt;Get the e-book: &lt;a href="https://developers.redhat.com/e-books/quarkus-spring-developers"&gt;Quarkus for Spring Developers&lt;/a&gt;&lt;/strong&gt; ]&lt;/p&gt; &lt;h2&gt;Simplifying the inner and outer loop&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session:&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=6-3xSNqwlG4&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=6"&gt;Java: Life is short&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href="https://developers.redhat.com/author/kevin-dubois"&gt;Kevin Dubois, Principal Developer Advocate&lt;/a&gt;&lt;/p&gt; &lt;p&gt;How can you speed up your development and spend time on things that are actually interesting instead of waiting for code compilations and deployments, fidgeting with configurations, or spending hours tracking down bugs on production?&lt;/p&gt; &lt;p&gt;In this talk, Developer Advocate Kevin Dubois takes you through the inner and outer development loop and shows you some interesting ways to simplify and accelerate development along the way. He provides examples and explanations to demonstrate an opinionated set of open source projects that can make life as a developer more enjoyable and productive.&lt;/p&gt; &lt;h2&gt;A new way to work with containers and Kubernetes&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session: &lt;/strong&gt;&lt;a href="https://www.youtube.com/watch?v=p1InzhcyCYE&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=5"&gt;Containers to pods to Kubernetes: Podman Desktop&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a href="https://developers.redhat.com/author/stevan-le-meur"&gt;Stévan Le Meur, Principal Product Manager&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Kubernetes has skyrocketed to the top as the premier platform for managing containers at scale. But let's face it—working with Kubernetes as a developer can be intimidating, especially if you're just starting their containerization journey. Local development environments tend to lack consistency with target Kubernetes environments, causing challenges in deploying and debugging your applications in production.&lt;/p&gt; &lt;p&gt;So how can you minimize this inconsistency as a developer and smoothly transition your application from your development desktop into production? Podman Desktop is the answer!&lt;/p&gt; &lt;p&gt;This talk from Stévan Le Meur introduces Podman Desktop, a powerful, cross-platform and open source graphical tool that simplifies container development workflows. He&lt;span&gt; explains how this cutting-edge tool can guide you through the journey from application to containers, to pods, and finally to Kubernetes. This is a must-see for anyone looking to streamline their container development process.&lt;/span&gt;&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;[ Learn more: &lt;a href="https://developers.redhat.com/articles/2023/03/01/podman-desktop-introduction"&gt;What is Podman Desktop? A developer's introduction&lt;/a&gt; ]&lt;/strong&gt;&lt;/p&gt; &lt;h2&gt;Fine-grained API authorization &lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session: &lt;/strong&gt;&lt;a href="https://www.youtube.com/watch?v=L4wHQwY-tIA&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=9"&gt;Fine-grained API Authorization using 3scale and authorization systems&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Abdelhamid Soliman, Senior Specialist Solution Architect, Application Services&lt;/p&gt; &lt;p&gt;In this talk, Abdelhamid Soliman explores the importance of fine-grained API authorization and how it can be achieved using Red Hat 3scale API Management and authorization systems such as Keycloak and Open Policy Agent (OPA). This talk covers the various types of authorization mechanisms and their benefits, as well as the challenges of implementing fine-grained authorization.&lt;/p&gt; &lt;h2&gt;Serverless computing: Benefits and drawbacks&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Session: &lt;/strong&gt;&lt;a href="https://www.youtube.com/watch?v=GSLxrsU4fdQ&amp;list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41&amp;index=19"&gt;Serverless computing: Explore the benefits and drawbacks of serverless computing and how to build serverless applications&lt;/a&gt;&lt;br /&gt;&lt;strong&gt;Speakers&lt;/strong&gt;: Steve Tran, Principal Consultant, and Jon Keam, Associate Principal Specialist Solution Architect, Application Platform&lt;/p&gt; &lt;p&gt;In this session, Steve Tran and Jon Keam discuss the advantages of serverless, including reduced costs, increased scalability, and faster development times. They explain the limitations of distributed monoliths and how the shift toward cloud and microservice architecture has highlighted these drawbacks. &lt;/p&gt; &lt;p&gt;Explore the benefits of using Quarkus to modernize legacy workloads, including streamlining development, enhancing performance, and lowering operational costs. This talk also provides valuable insights and considerations for organizations planning to modernize legacy workloads with Quarkus, ensuring a smooth and successful transition toward a more agile and scalable application infrastructure.&lt;/p&gt; &lt;h2&gt;Even more DevNation Day&lt;/h2&gt; &lt;p&gt;You can find more great sessions in our &lt;a href="https://www.youtube.com/playlist?list=PLf3vm0UK6HKpNrHaILLCMitayjfnCAy41"&gt;video playlist&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Visit the &lt;a href="https://developers.redhat.com/devnation/dnd"&gt;DevNation Day&lt;/a&gt; page on Red Hat Developer for upcoming events and even more video content. To see all upcoming DevNation events, check out the &lt;a href="https://developers.redhat.com/devnation#assembly-field-sections-85041"&gt;DevNation events calendar&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/28/devnation-day-modern-app-dev-videos-are-now-available" title="DevNation Day: Modern App Dev videos are now available"&gt;DevNation Day: Modern App Dev videos are now available&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Valentina Rodriguez Sosa</dc:creator><dc:date>2023-07-28T13:00:00Z</dc:date></entry><entry><title>How to use a Python multiprocessing module</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/27/how-use-python-multiprocessing-module" /><author><name>Rodolfo Olivieri</name></author><id>16267114-4448-4f0e-8d14-7b3bfbaf2a81</id><updated>2023-07-27T07:00:00Z</updated><published>2023-07-27T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we will learn how to work with a specific Python class from the &lt;a href="https://docs.python.org/3/library/multiprocessing.html"&gt;multiprocessing&lt;/a&gt; module, the &lt;a href="https://docs.python.org/3/library/multiprocessing.html#the-process-class"&gt;process&lt;/a&gt; class. I will give you a quick overview with examples.&lt;/p&gt; &lt;h2&gt;What is a Python multiprocessing module?&lt;/h2&gt; &lt;p&gt;What better way of describing what the module than to pull from the official documentation? &lt;a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing"&gt;&lt;span class="pre"&gt;Multiprocessing&lt;/span&gt;&lt;/a&gt; is a package that supports spawning processes using an API similar to the &lt;a href="https://docs.python.org/3/library/threading.html#module-threading"&gt;&lt;span class="pre"&gt;threading&lt;/span&gt;&lt;/a&gt; module. The &lt;a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing"&gt;&lt;span class="pre"&gt;multiprocessing&lt;/span&gt;&lt;/a&gt; package offers both local and remote concurrency, effectively side-stepping the &lt;a href="https://docs.python.org/3/glossary.html#term-global-interpreter-lock"&gt;&lt;span class="std std-term xref"&gt;Global Interpreter Lock&lt;/span&gt;&lt;/a&gt; by using subprocesses instead of threads.&lt;/p&gt; &lt;p&gt;The threading module is not the focus of this article, but in summary, the threading module will handle a small segment of code execution (lightweight and with shared memory), while the multiprocessing one will handle a program execution (heavier, and totally isolated).&lt;/p&gt; &lt;p&gt;If you want to learn more about the difference between a process and a thread, read this amazing article by Jong Hyuck Won, &lt;a href="https://medium.com/@denniswon/process-vs-thread-whats-the-difference-23cb30a772c4" target="_blank"&gt;Process vs Thread: What’s the difference?&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In general, the multiprocessing module offers a variety of other classes, functions and utilities that one could use to handle multiple processes executing during your program execution. That module is specially designed to be the main point of interaction if a program needs to apply parallelism in its workflow. We won't go over all classes and utilities from the multiprocessing module, but rather, we will focus on a very specific class, the &lt;a href="https://docs.python.org/3/library/multiprocessing.html#the-process-class"&gt;process&lt;/a&gt; class.&lt;/p&gt; &lt;h2&gt;What is the process class?&lt;/h2&gt; &lt;p&gt;In this section, we will try to give a better scope of what a process is, and how you can identify, use and manage processes within Python. As explained in the &lt;a href="https://www.gnu.org/software/libc/manual/html_node/Processes.html"&gt;GNU C Library&lt;/a&gt;: "Processes are the primitive units for allocation of system resources. Each process has its own address space and (usually) one thread of control. A process executes a program; you can have multiple processes executing the same program, but each process has its own copy of the program within its own address space and executes it independently of the other copies."&lt;/p&gt; &lt;p&gt;But what does that look like in Python? So far, we have managed to give some descriptions and references to what a process is, the difference between a process and a thread, but we haven't touched any code so far. Well, let's change that and do a very simple example of a process in Python:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os # A very, very simple process. if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Which will produce the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 144112 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see, any running Python script or program is a process of its own.&lt;/p&gt; &lt;h3&gt;Creating a child process from your parent&lt;/h3&gt; &lt;p&gt;And what about spawning different child processes inside your parent process? Well, to do that, we have the aid of the &lt;code&gt;Process&lt;/code&gt; class from multiprocessing module, and it looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(): print(f"Hi! I'm a child process {os.getpid()}") if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. process = multiprocessing.Process(target=child_process) # We then start the process process.start() # And finally, we join the process. This will make our script to hang and # wait until the child process is done. process.join() &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Which will produce the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 144078 Hi! I'm a child process 144079 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A very important note about the previous script: if you don't use the &lt;code&gt;process.join()&lt;/code&gt; to wait for your child process to execute and finish, then any other subsequent code that point will actually execute and may become a bit harder to synchronize your workflow.&lt;/p&gt; &lt;p&gt;Consider the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(): print(f"Hi! I'm a child process {os.getpid()}") if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. process = multiprocessing.Process(target=child_process) # We then start the process process.start() # And finally, we join the process. This will make our script to hang and # wait until the child process is done. #process.join() print("AFTER CHILD EXECUTION! RIGHT?!") &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This snippet will produce the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 145489 AFTER CHILD EXECUTION! RIGHT?! Hi! I'm a child process 145490&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Of course, it is not correct to affirm that the above snippet is wrong. It will all depend on how you want to use the module and how your child processes will execute. So use it wisely.&lt;/p&gt; &lt;h3&gt;Creating various child processes from a parent process&lt;/h3&gt; &lt;p&gt;If you want to spawn multiple processes, you can take advantage of for-loops (or any other type of loops). They will let you create as many references to the processes you need, and at a later stage, &lt;code&gt;start/join&lt;/code&gt;&lt;strong&gt; &lt;/strong&gt;them.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(id): print(f"Hi! I'm a child process {os.getpid()} with id#{id}") if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") list_of_processes = [] # Loop through the number 0 to 10 and create processes for each one of # them. for i in range(0, 10): # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. Note the difference now that # we are using the `args` parameter now, this means that we can pass # down parameters to the function being executed as a child process. process = multiprocessing.Process(target=child_process, args=(i,)) list_of_processes.append(process) for process in list_of_processes: # We then start the process process.start() # And finally, we join the process. This will make our script to hang # and wait until the child process is done. process.join() &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That will produce the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 146056 Hi! I'm a child process 146057 with id#0 Hi! I'm a child process 146058 with id#1 Hi! I'm a child process 146059 with id#2 Hi! I'm a child process 146060 with id#3 Hi! I'm a child process 146061 with id#4 Hi! I'm a child process 146062 with id#5 Hi! I'm a child process 146063 with id#6 Hi! I'm a child process 146064 with id#7 Hi! I'm a child process 146065 with id#8 Hi! I'm a child process 146066 with id#9&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Communicating data between child process and parent process&lt;/h3&gt; &lt;p&gt;In the previous section, I described the addition of a new parameter to the &lt;code&gt;multiprocessing.Process&lt;/code&gt; class constructor, the &lt;code&gt;args&lt;/code&gt;. This parameter allows you to pass down values to your child process to be used inside of the function. But do you know how to return data from the child process?&lt;/p&gt; &lt;p&gt;You may be thinking that to return data from the child, one must use the &lt;code&gt;return&lt;/code&gt; statement inside of it to actually be able to retrieve the data. A process is wonderful to execute functions in an isolated way, without interfering with shared resources meaning that the normal and usual way that we know about returning data from functions. Here, is not allowed because of its isolation.&lt;/p&gt; &lt;p&gt;Instead, we can use the &lt;a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue" target="_blank"&gt;queue&lt;/a&gt; class, which will provide us an interface to communicate data between the parent process and its child processes. A queue, in this context, is a normal FIFO (First In First Out) that has a built-in mechanism for working with multiprocessing.&lt;/p&gt; &lt;p&gt;Consider the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(queue, number1, number2): print(f"Hi! I'm a child process {os.getpid()}. I do calculations.") sum = number1 + number2 # Putting data into the queue queue.put(sum) if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") # Defining a new Queue() queue = multiprocessing.Queue() # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. Note the difference now that # we are using the `args` parameter now, this means that we can pass # down parameters to the function being executed as a child process. process = multiprocessing.Process(target=child_process, args=(queue,1, 2)) # We then start the process process.start() # And finally, we join the process. This will make our script to hang and # wait until the child process is done. process.join() # Accessing the result from the queue. print(f"Got the result from child process as {queue.get()}") &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It will give the following output:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 149002 Hi! I'm a child process 149003. I do calculations. Got the result from child process as 3 &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Exception handling for the process class&lt;/h3&gt; &lt;p&gt;Handling exceptions is a special and somewhat difficult task that we have to go through from time to time while working with the process module. The reason for that is, by default, any exception that occurs inside a child process will always be handled by the &lt;code&gt;Process&lt;/code&gt; class that spawned it.&lt;/p&gt; &lt;p&gt;The code below is raising an &lt;code&gt;Exception&lt;/code&gt; with text:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(): print(f"Hi! I'm a child process {os.getpid()}.") raise Exception("Oh no! :(") if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. Note the difference now that # we are using the `args` parameter now, this means that we can pass # down parameters to the function being executed as a child process. process = multiprocessing.Process(target=child_process) try: # We then start the process process.start() # And finally, we join the process. This will make our script to hang and # wait until the child process is done. process.join() print("AFTER CHILD EXECUTION! RIGHT?!") except Exception: print("Uhhh... It failed?") &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This results in:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[r0x0d@fedora ~]$ python /tmp/tmp.iuW2VAurGG/scratch.py Hi! I'm process 149505 Hi! I'm a child process 149506. Process Process-1: Traceback (most recent call last): File "/usr/lib64/python3.11/multiprocessing/process.py", line 314, in _bootstrap self.run() File "/usr/lib64/python3.11/multiprocessing/process.py", line 108, in run self._target(*self._args, **self._kwargs) File "/tmp/tmp.iuW2VAurGG/scratch.py", line 7, in child_process raise Exception("Oh no! :(") Exception: Oh no! :( AFTER CHILD EXECUTION! RIGHT?!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you follow up the code, you will be able to notice that there is a &lt;code&gt;print&lt;/code&gt; statement carefully placed after the &lt;code&gt;process.join()&lt;/code&gt; call to simulate that the parent process is still running, even after an unhandled exception raised in its child.&lt;/p&gt; &lt;p&gt;One way of overcoming this situation is to actually handle the exception inside your child process as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;#!/usr/bin/env python import os import multiprocessing def child_process(): try: print(f"Hi! I'm a child process {os.getpid()}.") raise Exception("Oh no! :(") except Exception: print("Uh, I think it's fine now...") if __name__ == "__main__": print(f"Hi! I'm process {os.getpid()}") # Here we create a new instance of the Process class and assign our # `child_process` function to be executed. Note the difference now that # we are using the `args` parameter now, this means that we can pass # down parameters to the function being executed as a child process. process = multiprocessing.Process(target=child_process) # We then start the process process.start() # And finally, we join the process. This will make our script to hang and # wait until the child process is done. process.join() print("AFTER CHILD EXECUTION! RIGHT?!") &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now your exceptions will be handled inside your child process, meaning you can control what will happen to it and what should be done in such cases.&lt;/p&gt; &lt;h2&gt;Final thoughts&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;multiprocessing&lt;/code&gt; module is very powerful when working and implementing solutions that will depend on executing in a parallel way, especially if used with the &lt;code&gt;Process&lt;/code&gt; class. That adds this amazing possibility to execute any function in its own isolated process.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/27/how-use-python-multiprocessing-module" title="How to use a Python multiprocessing module"&gt;How to use a Python multiprocessing module&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Rodolfo Olivieri</dc:creator><dc:date>2023-07-27T07:00:00Z</dc:date></entry><entry><title>Analysing Quarkus Native startup RSS consumption</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/native-startup-rss-troubleshooting/&#xA;            " /><author><name>Galder Zamarreño (https://twitter.com/galderz)</name></author><id>https://quarkus.io/blog/native-startup-rss-troubleshooting/</id><updated>2023-07-27T00:00:00Z</updated><published>2023-07-27T00:00:00Z</published><summary type="html">During the development of Quarkus 2.13, we discovered that there was a startup degradation in native mode. One of the key aspects of this degradation was that RSS consumption on start up had gone up by about 10-15% compared to Quarkus 2.7. In this blog post you will learn how...</summary><dc:creator>Galder Zamarreño (https://twitter.com/galderz)</dc:creator><dc:date>2023-07-27T00:00:00Z</dc:date></entry><entry><title>Manage Kafka clusters with AKHQ and AMQ streams</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/26/manage-kafka-clusters-akhq-and-amq-streams" /><author><name>Rogerio Santos</name></author><id>03c3e30e-2987-41f7-9c98-5197fc74dc70</id><updated>2023-07-26T07:00:00Z</updated><published>2023-07-26T07:00:00Z</published><summary type="html">&lt;p&gt;A Graphical User Interface, or GUI, is highly important for &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka&lt;/a&gt; administrators and developers. Having the ability to visualize and interact with topics or make changes quickly can save a significant amount of time. While Red Hat's &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;AMQ&lt;/a&gt; streams Operator is often considered a lightweight GUI, more advanced and detailed information can only be obtained using command-line tools such as &lt;code&gt;kafka-consumer-groups.sh&lt;/code&gt;, &lt;code&gt;kafka-acls.sh&lt;/code&gt;, etc.&lt;/p&gt; &lt;p&gt;In most of the customer implementations of Kafka clusters I have encountered, the most common question is: "Where is the web console?"&lt;/p&gt; &lt;p&gt;The answer to this question is simple: AMQ streams does not have a built-in GUI. However, there are many free and paid third-party options available that are fully compatible with AMQ streams. Among dozens of tools, one particular tool caught my attention: &lt;a href="https://akhq.io/"&gt;AKHQ&lt;/a&gt;. In this article, I will demonstrate how to deploy AKHQ on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; 4 and connect it to AMQ streams.&lt;/p&gt; &lt;h2&gt;The Kafka cluster&lt;/h2&gt; &lt;p&gt;The example Kafka cluster that I will use for this article has the following characteristics:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Authentication mechanism: &lt;code&gt;SCRAM-SHA-512&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Protocol: &lt;code&gt;SASL_SSL&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Sasl.jaas.config: &lt;code&gt;org.apache.kafka.common.security.scram.ScramLoginModule required username="akhq" password="NmfwVqrNZKyy";&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Namespace: &lt;code&gt;amq-streams-lab&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Kafka version: 3.3.1 with operator version v2.3.0-3&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;I will install AKHQ in the same namespace as AMQ streams because I want it to take over the GUI role solely for this Kafka installation. However, it would be fine to install it in a different namespace. One of the features of AKHQ is its support for configuring multiple clusters, making it a convenient central GUI for managing multiple Kafka clusters.&lt;/p&gt; &lt;h2&gt;Prepare the AKHQ package&lt;/h2&gt; &lt;p&gt;To begin, let's clone AKHQ from the following address: &lt;a href="https://github.com/tchiotludo/akhq.git"&gt;https://github.com/tchiotludo/akhq.git&lt;/a&gt;. The example shown in this article uses AKHQ version 0.24.0.&lt;/p&gt; &lt;p&gt;We'll perform the installation using Helm. Within the cloned project, there is a folder named &lt;code&gt;helm/akhq&lt;/code&gt;&lt;em&gt; &lt;/em&gt;containing everything necessary for deployment on OpenShift 4.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;git clone https://github.com/tchiotludo/akhq.git cd ./akhq/helm/akhq&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Within the folder, you will find a file named &lt;code&gt;values.yaml.&lt;/code&gt; Edit this file and fill in the Kafka cluster connection parameters. Locate the &lt;code&gt;secrets {}&lt;/code&gt; property, remove the comments, and fill it out as shown in the example below:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;secrets: akhq: connections: amqstreams-lab: properties: bootstrap.servers: "amqstreams-lab-kafka-bootstrap.amq-streams-lab.svc.cluster.local:9095" security.protocol: SASL_SSL sasl.mechanism: SCRAM-SHA-512 sasl.jaas.config: org.apache.kafka.common.security.scram.ScramLoginModule required username="akhq" password="NmfwVqrNZKyy"; ssl.truststore.location: /opt/kafka/cluster-ca-certs/ca.p12 ssl.truststore.password: bnnZ0bY9L79i&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;While configuring the &lt;code&gt;ssl.truststore.password&lt;/code&gt; and &lt;code&gt;ssl.truststore.location&lt;/code&gt; properties, it's essential to remember that these values will be retrieved from the Kafka cluster's certificate secret. Further clarity on this will be provided during the configuration of &lt;code&gt;extraVolumes&lt;/code&gt; and &lt;code&gt;extraVolumeMount&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Another necessary change is to adjust the service port. Locate the &lt;code&gt;service&lt;/code&gt; property and modify the value from &lt;code&gt;80&lt;/code&gt; to &lt;code&gt;8080&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;service: enabled: true type: ClusterIP port: 8080 managementPort: 28081 #httpNodePort: 32551 labels: {} annotations: # cloud.google.com/load-balancer-type: "Internal"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I'm utilizing a Kafka cluster that requires a certificate for authentication. Since I'm deploying AKHQ in the same namespace as AMQ streams, I'll configure AKHQ to retrieve the cluster certificate from the &lt;code&gt;secret&lt;/code&gt; associated with the cluster. Locate the &lt;code&gt;extraVolumeMounts&lt;/code&gt; and &lt;code&gt;extraVolumes&lt;/code&gt; properties and populate them as demonstrated below.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;# Any extra volumes to define for the pod (like keystore/truststore) extraVolumes: - name: cluster-ca-cert secret: secretName: amqstreams-lab-cluster-ca-cert defaultMode: 420 # Any extra volume mounts to define for the akhq container extraVolumeMounts: - name: cluster-ca-cert mountPath: /opt/kafka/cluster-ca-certs/ca.p12 subPath: ca.p12 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The password required for the &lt;code&gt;ssl.truststore.password&lt;/code&gt; property, mentioned earlier in this article, can be retrieved also from the secret named &lt;code&gt;amqstreams-lab-cluster-ca-cert&lt;/code&gt;. In each Kafka cluster, there exists a secret containing both its certificate and password, and the naming convention for this secret follows the structure &lt;code&gt;&lt;CLUSTER NAME&gt;.cluster-ca-cert&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The final essential configuration is to define the route for accessing AKHQ. In the &lt;code&gt;values.yaml&lt;/code&gt; file, locate the &lt;code&gt;ingress&lt;/code&gt; property, and populate it as shown below.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;ingress: enabled: true ingressClassName: "" annotations: {} # kubernetes.io/ingress.class: nginx # kubernetes.io/tls-acme: "true" paths: - / hosts: - akhq-amq-streams-lab.apps-crc.testing tls: [] # - secretName: akhq-tls # hosts: # - akhq.demo.com&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In this example, the host is composed of the following structure: &lt;code&gt;akhq + &lt;namespace name&gt; + &lt;Openshift host&gt;&lt;/code&gt;. You have the flexibility to include annotations, certificates, or any valid domain.&lt;/p&gt; &lt;h2&gt;Deploy and run&lt;/h2&gt; &lt;p&gt;To deploy AKHQ, I will use the Helm install &lt;name&gt; command, as shown below. (Note: I used Helm version 3.11. Check the syntax of &lt;code&gt;install&lt;/code&gt; in other versions.)&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc project amq-streams-lab helm install akhq-amqstreams  .&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The result of executing this command will be the following artifacts within the namespace:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;1 pod has been created with a name similar to &lt;code&gt;akhq-amqstreams-XXXXX&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1  deployment created with the name &lt;code&gt;akhq-amqstreams&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 secret created with the name &lt;code&gt;akhq-amqstreams-secrets&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 ConfigMap created with the name &lt;code&gt;akhq-amqstreams&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 replicaSet created with a name similar to &lt;code&gt;akhq-amqstreams-XXXXX&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 service created with the name &lt;code&gt;akhq-amqstreams&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 NetworkPolicy created with a name &lt;code&gt;akhq-amqstreams&lt;/code&gt;&lt;/li&gt; &lt;li&gt;1 route created with a name similar to &lt;code&gt;akhq-amqstreams-XXXXX&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;To access AHKQ, use the route created during the installation. You will see a screen similar to the one shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/akhq1.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/akhq1.png?itok=Q3J-vO1U" width="1440" height="766" alt="The AHKQ dashboard." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The AHKQ dashboard.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Now, you can navigate through the tool and enjoy the experience.&lt;/p&gt; &lt;h2&gt;Final considerations&lt;/h2&gt; &lt;p&gt;AKHQ is an excellent complement to AMQ streams. In this article, I provided a quick start guide. However, you can enhance this installation by incorporating additional features such as implementing a login using Red Hat's single sign-on tool, creating a service account, or scaling up the number of pods. You can even customize the appearance by adding a new logo to enhance the user experience further.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/26/manage-kafka-clusters-akhq-and-amq-streams" title="Manage Kafka clusters with AKHQ and AMQ streams"&gt;Manage Kafka clusters with AKHQ and AMQ streams&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Rogerio Santos</dc:creator><dc:date>2023-07-26T07:00:00Z</dc:date></entry><entry><title>End-to-end testing with self-hosted runners in GitHub Actions</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/07/25/end-end-testing-self-hosted-runners-github-actions" /><author><name>Jianzhu Zhang, Andrew Kiselev, Daniel Kostecki</name></author><id>86833e73-bbec-48eb-8325-912250049ea6</id><updated>2023-07-25T07:00:00Z</updated><published>2023-07-25T07:00:00Z</published><summary type="html">&lt;p&gt;Accelerating the software development life cycle while ensuring the quality and performance of applications is a challenging task. GitHub Actions makes it easy to automate all required CI software workflows for your GitHub repository.&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/actions/runner"&gt;GitHub Actions Runner&lt;/a&gt; is an application that runs a job from a GitHub Actions workflow. GitHub Actions also provides a self-hosted runner that allows you to run &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;continuous integration (CI)&lt;/a&gt; tests that require actual hardware. End-to-end testing (E2E testing) is a popular methodology to test an application's functionality and performance under real-life conditions. Still, it often demands actual hardware, rendering it infeasible to run on the public cloud.&lt;/p&gt; &lt;p&gt;In this article, we'll delve into our experience performing E2E testing for an open source project on-premises using a containerized self-hosted runner. The self-hosted runner &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; image used in this tutorial is available for download from the &lt;a href="quay.io/gitaction/runner"&gt;quay.io registry&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Self-hosted runner container on Red Hat Enterprise Linux&lt;/h2&gt; &lt;p&gt;First, we'll create a self-hosted runner container on &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL).&lt;/p&gt; &lt;h3&gt;Build and download the containerized runner image&lt;/h3&gt; &lt;p&gt;The whole procedure is covered in &lt;a href="https://github.com/redhat-eets/gitaction"&gt;https://github.com/redhat-eets/gitaction&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To build the containerized runner for a given runner version, enter the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman build --build-arg RUNNER_VERSION=2.301.1 --tag quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To see what runner releases are available to use for &lt;code&gt;RUNNER_VERSION&lt;/code&gt;, check on&lt;a href="https://github.com/actions/runner/releases"&gt; https://github.com/actions/runner/releases&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Alternatively, you can download a specific self-hosted runner container image for the 2.301.1 release:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman pull quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The GitHub runner will check if a newer version is available on startup. It will self-update and restart with the latest version. However, it is worth using the latest version for the container image. Note that the runner's self-update takes time and may not always be successful.&lt;/p&gt; &lt;h3&gt;GitHub token protection&lt;/h3&gt; &lt;p&gt;In order to generate a registration token, the container requires you to enter a &lt;a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token"&gt;GitHub personal access token&lt;/a&gt; (PAT) when starting. The PAT has to belong to the target repository owner for the container to register successfully.&lt;/p&gt; &lt;p&gt;From a security perspective, using the PAT directly with the Podman command is not a good idea. Instead, a Podman secret should be created for the PAT:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;echo "your github access token" &gt; token &amp;&amp; podman secret create github_token token &amp;&amp; rm -rf token&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the above step, &lt;code&gt;github_token&lt;/code&gt; must be used as the secret name, as this is the default secret filename that the script inside the container will look for. If you want to choose a different secret name, you can use the environment variable &lt;code&gt;GH_TOKEN_PATH&lt;/code&gt; to specify the secret file path when running Podman to start the container.&lt;/p&gt; &lt;p&gt;With all the information we have so far, run the self-hosted runner with Podman:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman run --secret github_token --name runner -it --rm --privileged -e GH_OWNER='&lt;your github id&gt;' -e GH_REPOSITORY='&lt;repo name&gt;' quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If using a different Podman secret name, say &lt;code&gt;some_github_token&lt;/code&gt;, use the extra environment variable &lt;code&gt;GH_TOKEN_PATH&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman run --secret some_github_token --name runner -it --rm --privileged -e GH_OWNER='&lt;your github id&gt;' -e GH_REPOSITORY='&lt;repo name&gt;' -e GH_TOKEN_PATH=/run/secrets/some_github_token quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Pass in extra information&lt;/h3&gt; &lt;p&gt;In reality, E2E CI workflows often require extra information outside of the target GitHub repository.&lt;/p&gt; &lt;p&gt;For illustrative purposes, we use the &lt;a href="https://github.com/redhat-partner-solutions/rhel-sriov-test"&gt;RHEL SR-IOV test suite&lt;/a&gt; as an example throughout this article. Its E2E CI workflow requires testbed information. The testbed information is not checked into the GitHub repository. For the runner container to access this information, a volume mount can be used. You can apply the same technique in &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To set up the volume mount for this purpose, first create a folder on the host and copy the required files into this folder. For the RHEL SR-IOV E2E CI, the required files are &lt;code&gt;testbed.yaml&lt;/code&gt; and &lt;code&gt;config.yaml&lt;/code&gt;, so copy these files into the folder and start the container with the volume mount:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;sudo mkdir -p /opt/E2E-config sudo cp testbed.yaml /opt/E2E-config sudo cp config.yaml /opt/E2E-config sudo chown -R nobody:nobody /opt/E2E-config podman run --secret github_token --name runner -it --rm --privileged -e GH_OWNER='redhat-partner-solutions' -e GH_REPOSITORY='rhel-sriov-test' -v /opt/E2E-config:/config quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the above sample step, the volume is mounted to &lt;code&gt;/config&lt;/code&gt; inside the container. That means the E2E CI workflow needs to go to this folder to retrieve these YAML files. Interested readers can take a look at the following &lt;a href="https://github.com/redhat-partner-solutions/rhel-sriov-test/blob/main/.github/workflows/e2e.yaml"&gt;E2E CI workflow&lt;/a&gt; for reference.&lt;/p&gt; &lt;h3&gt;Label the runner&lt;/h3&gt; &lt;p&gt;A GitHub repo can have multiple containerized runners on the same server using different labels. This is useful if various tests have different hardware requirements; for example, 800-series and 700-series Intel NICs:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman run --secret github_token --name runner810 -it --rm --privileged -e RUNNER_LABEL='810' -e GH_OWNER='redhat-partner-solutions' -e GH_REPOSITORY='rhel-sriov-test' -v /opt/E2E-config-810:/config quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman run --secret github_token --name runner710 -it --rm --privileged -e RUNNER_LABEL='710' -e GH_OWNER='redhat-partner-solutions' -e GH_REPOSITORY='rhel-sriov-test' -v /opt/E2E-config-710:/config quay.io/gitaction/runner:2.301.1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can refer to the runners above as &lt;code&gt;runs-on: [self-hosted, 810]&lt;/code&gt; or &lt;code&gt;runs-on: [self-hosted, 710]&lt;/code&gt;  in a GitHub workflow. &lt;/p&gt; &lt;p&gt;How to use the runner label will be explained later in the &lt;strong&gt;How to trigger the CI&lt;/strong&gt; section.&lt;/p&gt; &lt;h3&gt;Self-hosted runner as a systemd service&lt;/h3&gt; &lt;p&gt;Directly using the Podman command line to start the runner container primarily serves the purpose of proof of concept. For production use, you can use a &lt;a href="https://developers.redhat.com/cheat-sheets/systemd-commands-cheat-sheet"&gt;systemd&lt;/a&gt; service to manage the self-hosted runner. Here is the systemd unit file that was used by the RHEL SR-IOV E2E CI:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[Unit] Description=github self runner in container After=network.target [Service] Type=simple ExecStart=/usr/bin/podman run --secret github_token --name runner --rm --privileged -e GH_OWNER='redhat-partner-solutions' -e GH_REPOSITORY='rhel-sriov-test' -v /opt/E2E-config:/config quay.io/gitaction/runner:2.301.1 ExecStop=/usr/bin/podman stop runner [Install] WantedBy=multi-user.target&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After the container starts and successfully registers with the target GitHub repository, the self-hosted runner can be found under the target repository's Actions/Runners, as shown in Figure 1:&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-embedded"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;div class="field__item"&gt; &lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/runners.png" width="1086" height="582" alt="Runners" typeof="Image" /&gt;&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The self-hosted runner listed in the repository.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;How to trigger the CI&lt;/h2&gt; &lt;p&gt;Here is the sample code for using the runner label:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;name: sriov-e2e-test run-name: sriov-e2e-test initiated by ${{ github.actor }} on: pull_request: types: [ labeled ] workflow_dispatch: inputs: tag: description: 'NIC hardware' required: true default: '810' type: choice options: - 810 - 710 jobs: prepare-label: runs-on: ubuntu-latest outputs: label: ${{ steps.step1.outputs.label }} steps: - name: Check label id: step1 run: | if [ ${{ github.event.label.name }} == 'e2e-test' ]; then echo "label=810" &gt;&gt; $GITHUB_OUTPUT elif [ ${{ github.event.label.name }} == 'e2e-test-710' ]; then echo "label=710" &gt;&gt; $GITHUB_OUTPUT elif [ -n ${{ github.event.inputs.tag }} ]; then echo "label=${{ github.event.inputs.tag }}" &gt;&gt; $GITHUB_OUTPUT fi&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Using a label to trigger an E2E CI action&lt;/h3&gt; &lt;p&gt;As illustrated in the above sample code, one option to trigger the E2E test is to use the appropriate label, &lt;code&gt;e2e-test&lt;/code&gt; or &lt;code&gt;e2e-test-710&lt;/code&gt; (see Figure 2). This labeling mechanism serves as a way to limit who can trigger the E2E runs due to hardware resource constraints. Only repo users with write permission can set a pull request label and trigger the E2E test execution.  &lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-embedded"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;div class="field__item"&gt; &lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/labels.png" width="324" height="104" alt="Labels" typeof="Image" /&gt;&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Triggering a E2E test run with the e2e-test label.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The labels double as a flag showing which PRs have been tested. &lt;/p&gt; &lt;h3&gt;On-demand triggering&lt;/h3&gt; &lt;p&gt;In addition to the labeling above, we can also trigger this E2E action on demand. NIC hardware labels (810 or 710) are collected from the user input, in this case, and used to trigger the appropriate runner.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-embedded"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;div class="field__item"&gt; &lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/e2e_hw_sel_0.png" width="1181" height="522" alt="On demand" typeof="Image" /&gt;&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Self-hosted runner as an OpenShift Workload&lt;/h2&gt; &lt;p&gt;If the test environment already has an OpenShift/&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; cluster installed, and the user does not plan to add an extra RHEL server to host the runner systemd service, the runner container can be hosted on the OpenShift/Kubernetes cluster instead. In this situation, the self-hosted runner will be a workload in the pod format.&lt;/p&gt; &lt;p&gt;To use the runner container as an OpenShift workload for controlling an on-premise E2E CI testbed, the OpenShift cluster needs to be on-premise and have connectivity to the E2E CI testbed.&lt;/p&gt; &lt;p&gt;We will need to take steps to protect the user's PAT and pass in extra test configuration, similar to the runner container.&lt;/p&gt; &lt;h3&gt;GitHub token protection&lt;/h3&gt; &lt;p&gt;In OpenShift, create a secret for the PAT:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kubectl create secret generic gh-token --from-literal=github_token=&lt;your github token&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the above command, the name &lt;code&gt;github_token&lt;/code&gt; is used for the same reason explained earlier in the podman usage.&lt;/p&gt; &lt;p&gt;The secret &lt;code&gt;gh-token&lt;/code&gt; will be mounted as a volume later in the runner pod YAML spec.&lt;/p&gt; &lt;h3&gt;Pass in extra information&lt;/h3&gt; &lt;p&gt;Once again using the &lt;a href="https://github.com/redhat-partner-solutions/rhel-sriov-test"&gt;RHEL SR-IOV test suite repository&lt;/a&gt; for demo purposes, its E2E CI workflow requires &lt;code&gt;testbed.yaml&lt;/code&gt; and &lt;code&gt;config.yaml&lt;/code&gt; files, which can be passed to the runner pod via a volume map.&lt;/p&gt; &lt;p&gt;First, create a folder and store the required files under this folder:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ls /opt/E2E-config config.yaml testbed.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a ConfigMap from this folder:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc create configmap test-config --from-file=/opt/E2E-config&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This ConfigMap, &lt;code&gt;test-config&lt;/code&gt;, will be used in the volume map of the runner pod YAML spec.&lt;/p&gt; &lt;h3&gt;Self-hosted runner in deployment&lt;/h3&gt; &lt;p&gt;We will let OpenShift take care of the runner pod lifecycle management using a deployment. Here is the self-hosted runner deployment YAML spec:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: apps/v1 kind: Deployment metadata: name: runner-deployment labels: app: runner spec: replicas: 1 selector: matchLabels: app: runner template: metadata: labels: app: runner spec: volumes: - name: secret-volume secret: secretName: gh-token - name: config-volume configMap: name: test-config containers: - name: runner image: quay.io/gitaction/runner:2.301.1 securityContext: privileged: true env: - name: GH_OWNER value: "redhat-partner-solutions" - name: GH_REPOSITORY value: "rhel-sriov-test" - name: GH_TOKEN_PATH value: "/etc/gh_secrets/github_token" volumeMounts: - name: secret-volume readOnly: true mountPath: "/etc/gh_secrets" - name: config-volume mountPath: "/config"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notice in the above YAML spec the OpenShift secret &lt;code&gt;gh-token&lt;/code&gt; is mounted to the path &lt;code&gt;/etc/gh_secrets&lt;/code&gt;, so the environment variable &lt;code&gt;GH_TOKEN_PATH&lt;/code&gt; is used to tell the container to retrieve the secret from this path.&lt;/p&gt; &lt;p&gt;The extra information for the E2E CI testbed is mounted under &lt;code&gt;/config&lt;/code&gt;. As explained earlier, the E2E workflow will look for the extra information in that folder inside the container.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;We reviewed E2E CI building blocks which allow real hardware test execution for a GitHub open source project. Lightweight GitHub Actions CI, along with the containerized GitHub Actions runner, allow minimizing system footprint while maintaining CI functionality. Furthermore, this CI implementation fits well into corporate IT security policy for lab access: nothing extra gets exposed to the internet.&lt;/p&gt; &lt;p&gt;Feel free to comment below if you have questions. We welcome your feedback!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/07/25/end-end-testing-self-hosted-runners-github-actions" title="End-to-end testing with self-hosted runners in GitHub Actions"&gt;End-to-end testing with self-hosted runners in GitHub Actions&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Jianzhu Zhang, Andrew Kiselev, Daniel Kostecki</dc:creator><dc:date>2023-07-25T07:00:00Z</dc:date></entry></feed>
